{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82bd7948",
   "metadata": {},
   "source": [
    "# Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup & imports ---\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802545a1",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a558bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repro\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --- Load data ---\n",
    "data_dir = Path(\"../data\")\n",
    "\n",
    "with open(data_dir / \"train_data.pkl\", \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open(data_dir / \"test_data.pkl\", \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "train_images = train_data[\"images\"]          # (1080, 28, 28, 3)\n",
    "train_labels = train_data[\"labels\"].reshape(-1).astype(int)  # (1080,)\n",
    "test_images  = test_data[\"images\"]          # (400, 28, 28, 3)\n",
    "\n",
    "print(\"Train images:\", train_images.shape)\n",
    "print(\"Train labels:\", train_labels.shape, \"unique:\", np.unique(train_labels, return_counts=True))\n",
    "print(\"Test images:\", test_images.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a9b827",
   "metadata": {},
   "source": [
    "# Stratified Split Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_train_val_split(y, val_ratio=0.2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    classes = np.unique(y)\n",
    "    train_idxs = []\n",
    "    val_idxs = []\n",
    "\n",
    "    for c in classes:\n",
    "        idxs = np.where(y == c)[0]\n",
    "        np.random.shuffle(idxs)\n",
    "        n_val = int(len(idxs) * val_ratio)\n",
    "        val_idxs.append(idxs[:n_val])\n",
    "        train_idxs.append(idxs[n_val:])\n",
    "\n",
    "    train_idxs = np.concatenate(train_idxs)\n",
    "    val_idxs = np.concatenate(val_idxs)\n",
    "    np.random.shuffle(train_idxs)\n",
    "    np.random.shuffle(val_idxs)\n",
    "\n",
    "    return train_idxs, val_idxs\n",
    "\n",
    "train_idx, val_idx = stratified_train_val_split(train_labels, val_ratio=0.2)\n",
    "print(\"Train idx:\", train_idx.shape, \"Val idx:\", val_idx.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29678d7b",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet stats for ResNet18\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "class RetinaDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, transform=None):\n",
    "        \"\"\"\n",
    "        images: np.array (N, H, W, C)\n",
    "        labels: np.array (N,) or None for test\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]              # (H, W, C), uint8\n",
    "        img = Image.fromarray(img)          # -> PIL\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.labels is None:\n",
    "            return img\n",
    "\n",
    "        label = int(self.labels[idx])\n",
    "        return img, label\n",
    "\n",
    "# Build datasets using the same split as before\n",
    "full_train_dataset = RetinaDataset(train_images, train_labels, transform=train_transform)\n",
    "\n",
    "val_dataset_images = train_images[val_idx]\n",
    "val_dataset_labels = train_labels[val_idx]\n",
    "\n",
    "train_dataset = Subset(full_train_dataset, train_idx)\n",
    "val_dataset = RetinaDataset(val_dataset_images, val_dataset_labels, transform=val_test_transform)\n",
    "test_dataset = RetinaDataset(test_images, labels=None, transform=val_test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                          shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                           shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07804fd",
   "metadata": {},
   "source": [
    "# Resnet18 Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e13ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "def create_resnet18(num_classes=5, pretrained=True, device=device):\n",
    "    from torchvision import models\n",
    "    try:\n",
    "        from torchvision.models import ResNet18_Weights\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        model = models.resnet18(weights=weights)\n",
    "    except Exception:\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "\n",
    "    in_features = model.fc.in_features\n",
    "    # Add dropout before final linear layer\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "\n",
    "    # Freeze everything\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # Unfreeze deeper part + head\n",
    "    for p in model.layer3.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.layer4.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.fc.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "def train_model(model, train_loader, val_loader,\n",
    "                num_epochs=30,\n",
    "                lr_head=1e-3,\n",
    "                lr_backbone=1e-4,\n",
    "                weight_decay=1e-4,\n",
    "                patience=6,\n",
    "                device=device):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Split parameters: backbone vs head (fc)\n",
    "    backbone_params, head_params = [], []\n",
    "    for name, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "        if name.startswith(\"fc.\"):\n",
    "            head_params.append(p)\n",
    "        else:\n",
    "            backbone_params.append(p)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {\"params\": backbone_params, \"lr\": lr_backbone},\n",
    "            {\"params\": head_params, \"lr\": lr_head},\n",
    "        ],\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": [],\n",
    "    }\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ----- Train -----\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "            running_total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / running_total\n",
    "        train_acc = running_correct / running_total\n",
    "\n",
    "        # ----- Validation -----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss = val_loss / val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d} | \"\n",
    "            f\"train_loss={train_loss:.4f} val_loss={val_loss:.4f} | \"\n",
    "            f\"train_acc={train_acc:.4f} val_acc={val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Early stopping on val_acc\n",
    "        if val_acc > best_val_acc + 1e-4:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            patience_counter = 0\n",
    "            # store on CPU\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\n",
    "                    f\"Early stopping at epoch {epoch}, \"\n",
    "                    f\"best val_acc={best_val_acc:.4f} (epoch {best_epoch})\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    print(f\"Best val_acc={best_val_acc:.4f} at epoch {best_epoch}\")\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# ---- Train once with a solid default config ----\n",
    "model = create_resnet18(num_classes=5, pretrained=True)\n",
    "\n",
    "model, history = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=30,\n",
    "    lr_head=5e-4,\n",
    "    lr_backbone=5e-5,\n",
    "    weight_decay=5e-4,\n",
    "    patience=6,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe24f5",
   "metadata": {},
   "source": [
    "## Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np # Needed for np.arange\n",
    "\n",
    "hist_df = pd.DataFrame(history)\n",
    "sns.set_theme(style=\"whitegrid\", rc={\"grid.linestyle\": \"--\", \"grid.alpha\": 0.6})\n",
    "\n",
    "# --- Loss curves ---\n",
    "plt.figure(figsize=(10, 4)) # Increased figure size slightly to accommodate more ticks\n",
    "sns.lineplot(data=hist_df, x=\"epoch\", y=\"train_loss\", label=\"train\", linewidth=1.5)\n",
    "sns.lineplot(data=hist_df, x=\"epoch\", y=\"val_loss\", label=\"val\", linewidth=1.5)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"ResNet18 – Loss Curves\")\n",
    "plt.legend()\n",
    "\n",
    "# --- Control the X-axis Ticks ---\n",
    "plt.xticks(np.arange(0, len(hist_df) + 2, 2)) # Ticks for every epoch\n",
    "\n",
    "# Rotate ticks for readability if they overlap\n",
    "plt.xticks(rotation=45) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Accuracy curves ---\n",
    "plt.figure(figsize=(10, 4)) # Increased figure size slightly\n",
    "sns.lineplot(data=hist_df, x=\"epoch\", y=\"train_acc\", label=\"train\", linewidth=2.5)\n",
    "sns.lineplot(data=hist_df, x=\"epoch\", y=\"val_acc\", label=\"val\", linewidth=2.5)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"ResNet18 – Accuracy Curves\")\n",
    "plt.legend()\n",
    "\n",
    "# --- Control the X-axis Ticks ---\n",
    "plt.xticks(np.arange(0, len(hist_df) + 2, 2)) # Ticks for every epoch\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a105e6",
   "metadata": {},
   "source": [
    "# Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088736c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "\n",
    "y_test_pred = np.concatenate(all_preds)\n",
    "print(\"Test preds shape:\", y_test_pred.shape,\n",
    "      \"unique:\", np.unique(y_test_pred, return_counts=True))\n",
    "\n",
    "ids = np.arange(1, len(y_test_pred) + 1)\n",
    "sub = pd.DataFrame({\"ID\": ids, \"Label\": y_test_pred})\n",
    "sub.to_csv(\"m2_resnet18_regdrop_submission.csv\", index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
